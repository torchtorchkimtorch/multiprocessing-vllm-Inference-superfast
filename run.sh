python inference.py \
    --gpu_ids 1,2 \
    --model_path Qwen/Qwen3-4B \
    --input_path /data_x/mhkim0929/PR/data/debug.jsonl \
    --output_path /data_x/mhkim0929/PR/result \
    --output_name debug \
    --chat_field chat \
    --gen_field generated \
    --chunk_size 1000 \
    --save_every 200 \
    --max_new_tokens 4096 \
    --max_model_len 8192 \
    --temperature 0.6 \
    --top_k 20 \
    --top_p 0.95 \
    --reasoning enable_thinking=True